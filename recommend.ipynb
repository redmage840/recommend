{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python User-User Collaborative Filtering Recommender System\n",
    "# consider not using pivot table?\n",
    "# experiment with different similarity functions\n",
    "\n",
    "# KNeighbors-based solution\n",
    "# - For each unrated gameID that a userID has,\n",
    "# - Take K-Nearest Neighbors, (Experiment with different values of K)\n",
    "# - Add each Neighbor's RatingTimesSimilarityWeight, divide by K\n",
    "# - Predict should return the gameIDs that have the highest scores from unrated gameIDs (top N versus some threshold)\n",
    "\n",
    "# VERSUS BELOW (slight difference in step 3)\n",
    "\n",
    "'''\n",
    "1.) We have an n X m matrix consisting of the ratings of n users and m items. Each element of the matrix (i, j) \n",
    "represents how user i rated item j. Since we are working with movie ratings, each rating can be expected to be an \n",
    "integer from 1-5 (reflecting one-star ratings to five-star ratings) if user i has rated movie j, and 0 if the user \n",
    "has not rated that particular movie.\n",
    "\n",
    "2.) For each user, we want to recommend a set of movies that they have not seen yet (the movie rating is 0). \n",
    "To do this, we will effectively use an approach that is similar to weighted K-Nearest Neighbors.\n",
    "\n",
    "3.) For each movie j user i has not seen yet, we find the set of users U who are similar to user i and have seen \n",
    "movie j.\n",
    "For each similar user u, we take u's rating of movie j and multiply it by the cosine similarity \n",
    "of user i and user u. Sum up these weighted ratings, divide by the number of users in U, and we get a\n",
    "weighted average rating for the movie j.\n",
    "\n",
    "4.) Finally, we sort the movies by their weighted average rankings. These average rankings serve as an estimate\n",
    "for what the user will rate each movie. Movies with higher average rankings are more likely to be favored by the\n",
    "user, so we will recommend the movies with the highest average rankings to the user.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Read CSV and change to pivot_table\n",
    "df = pd.read_csv('inputs/boardgame-elite-users.csv')\n",
    "df = df.pivot_table(index='userID', columns='gameID', values='rating')\n",
    "\n",
    "# Fill nan with zero. Normalize ignores the zeroes\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test / Train Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize User Ratings for GameIDs\n",
    "normalized = normalize(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get User Similarity Matrix\n",
    "# Also try Pearson coefficient, city-block, etc...\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "sim = cosine_similarity(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.48283724 0.51777116 ... 0.4351639  0.46496088 0.43789763]\n",
      " [0.48283724 1.         0.787925   ... 0.68971905 0.76159997 0.76200811]\n",
      " [0.51777116 0.787925   1.         ... 0.66907022 0.77862168 0.74296635]\n",
      " ...\n",
      " [0.4351639  0.68971905 0.66907022 ... 1.         0.69099785 0.73612033]\n",
      " [0.46496088 0.76159997 0.77862168 ... 0.69099785 1.         0.75700164]\n",
      " [0.43789763 0.76200811 0.74296635 ... 0.73612033 0.75700164 1.        ]]\n",
      "9\n",
      "0.5462166510952147\n",
      "0.5524040756784209\n",
      "0.5530834950294008\n",
      "0.5532022766035907\n",
      "0.5554924637714952\n",
      "0.5573424146367286\n",
      "0.5803093270234448\n",
      "0.5833278622108075\n",
      "0.5953403235711451\n"
     ]
    }
   ],
   "source": [
    "# Get K nearest neighbors\n",
    "# argsort returns indices of the values of a sorted version of the array\n",
    "nrst10_nbors = sim.argsort()[:,-10:-1]\n",
    "\n",
    "print(sim)\n",
    "print(len(nrst10_nbors[0]))\n",
    "for x in nrst10_nbors[0]:\n",
    "    print(sim[0][x])\n",
    "for x in nrst10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
